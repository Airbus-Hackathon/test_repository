# Test

This repository contains the code for the model evaluation. It uses the airbus provided evaluation script under the hood. It only serves as a practical and generic tool to evaluate a model.

## Warning

It seems there is no reference text in the test dataset (test_set.json) provided on the 25/02/2024 thus our evaluation can't be done between the reference text and summary generated by our model.

## How does it work 

The [evaluate script](./evaluate/executetest.py) will use the model located in the [checkpoints folder](./checkpoints) (the one to create and where you place the model into - see below).
and use the generated [test set file](./datasets/test/test_set.json) as an input file on which it will produce summary using the model, then the evaluation script will be launched automatically and generate reports that will be placed under the [evaluation reports folder](./evaluations%20reports/)

## Download the model checkpoint file

[download the output.ckpt file](https://drive.usercontent.google.com/download?id=1U6mFv9Q4EbBwaqzqP0jSRI85fkCAGtUL&export=download)

Please rename the file to: output.ckpt and place it into the ./checkpoints directory

## Start in development

```bash
# create a checkpoints directory at root of the directory
mkdir -p ./checkpoints
# install dependencies
cd evaluate && pip install -r requirements.txt
python ./executetest.py
```
